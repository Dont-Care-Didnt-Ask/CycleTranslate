{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6415478-abfa-4629-bd2b-2dd99b97a543",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6380081c-a3c9-43c1-bacd-263d3e14b946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=4\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac1348c5-3fdf-49b8-9e3a-3467bb89cd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "import evaluate\n",
    "\n",
    "%config InlineBackend.figure_format = \"svg\"\n",
    "plt.rcParams[\"figure.figsize\"] = 10, 6\n",
    "\n",
    "SEED = 44\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd17aa7-eaed-4cbe-a012-a30106234c23",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c60e295-889b-4cf4-8926-42133c363ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/rus.txt\", sep=\"\\t\", names=[\"en\", \"ru\", \"attribution\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c581c5b9-7f87-4a4c-8d87-a40f35f08d92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>ru</th>\n",
       "      <th>attribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>397801</th>\n",
       "      <td>Tom doesn't want to live in the country.</td>\n",
       "      <td>Фома не хочет жить в сельской местности.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117848</th>\n",
       "      <td>You'd better sit here.</td>\n",
       "      <td>Вам лучше сесть здесь.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238444</th>\n",
       "      <td>I read about it in the paper.</td>\n",
       "      <td>Я прочёл об этом в газете.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191284</th>\n",
       "      <td>Where are you going to go?</td>\n",
       "      <td>Куда ты собираешься идти?</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295363</th>\n",
       "      <td>I'd like to know the exact time.</td>\n",
       "      <td>Я хотел бы знать точное время.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              en   \n",
       "397801  Tom doesn't want to live in the country.  \\\n",
       "117848                    You'd better sit here.   \n",
       "238444             I read about it in the paper.   \n",
       "191284                Where are you going to go?   \n",
       "295363          I'd like to know the exact time.   \n",
       "\n",
       "                                              ru   \n",
       "397801  Фома не хочет жить в сельской местности.  \\\n",
       "117848                    Вам лучше сесть здесь.   \n",
       "238444                Я прочёл об этом в газете.   \n",
       "191284                 Куда ты собираешься идти?   \n",
       "295363            Я хотел бы знать точное время.   \n",
       "\n",
       "                                              attribution  \n",
       "397801  CC-BY 2.0 (France) Attribution: tatoeba.org #2...  \n",
       "117848  CC-BY 2.0 (France) Attribution: tatoeba.org #1...  \n",
       "238444  CC-BY 2.0 (France) Attribution: tatoeba.org #2...  \n",
       "191284  CC-BY 2.0 (France) Attribution: tatoeba.org #1...  \n",
       "295363  CC-BY 2.0 (France) Attribution: tatoeba.org #2...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(5, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2830161-1b3c-4729-a1e5-17e3154ca863",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = data.sample(1000, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01a000cb-3077-4ee5-b880-c420337ac016",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainval, test = train_test_split(data, test_size=0.2, random_state=SEED)\n",
    "train, val = train_test_split(trainval, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "278c6748-b882-4519-bcbd-fbe327546e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"cointegrated/rut5-base\"\n",
    "\n",
    "tokenizer = transformers.T5Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "def tokenize_data(data, tokenizer): \n",
    "    english_tokenized = None if \"en\" not in data else tokenizer(data[\"en\"].tolist(), truncation=True, max_length=36)\n",
    "    russian_tokenized = None if \"ru\" not in data else tokenizer(data[\"ru\"].tolist(), truncation=True, max_length=36)\n",
    "\n",
    "    return english_tokenized, russian_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf14ef1-9e87-479b-89b2-73b4e245c162",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tokenized = {\n",
    "    \"train\": tokenize_data(train, tokenizer),\n",
    "    \"val\": tokenize_data(val, tokenizer),\n",
    "    \"test\": tokenize_data(test, tokenizer),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa39096-b752-4c53-b2e2-c1a74952b952",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranslationDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, english, russian):\n",
    "        super().__init__()\n",
    "        self.english = english\n",
    "        self.russian = russian\n",
    "        \n",
    "        assert english is not None or russian is not None\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        item = {}\n",
    "\n",
    "        if self.english is not None:\n",
    "            item[\"input_ids\"] = torch.tensor(self.english[\"input_ids\"][index], dtype=torch.long)\n",
    "            item[\"attention_mask\"] = torch.tensor(self.english[\"attention_mask\"][index])\n",
    "        \n",
    "        if self.russian is not None:\n",
    "            item[\"labels\"] = torch.tensor(self.russian[\"input_ids\"][index], dtype=torch.long)\n",
    "            item[\"labels_attention_mask\"] = torch.tensor(self.russian[\"attention_mask\"][index])\n",
    "\n",
    "        assert len(item) > 0\n",
    "        \n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.english[\"input_ids\"]) if self.english is not None else len(self.russian[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3ece78-3fb5-4106-aadd-ac18f9a118c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TranslationDataset(*tokenized[\"train\"])\n",
    "val_ds = TranslationDataset(*tokenized[\"val\"])\n",
    "test_ds = TranslationDataset(*tokenized[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2897842-756e-49bb-8c12-66c04d403048",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3866e7b0-5058-42cf-98c6-002eb71240fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.all_special_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d9661e-942e-4db6-997b-024c7c131bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.all_special_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a932142-9e76-490a-b006-88cb7a93779d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def collator(examples):\n",
    "    #print(\"N examples:\", len(examples))\n",
    "    #print(\"First example:\", examples[0])\n",
    "    \n",
    "    batch_keys = examples[0].keys()\n",
    "\n",
    "    batch = {key: pad_sequence([sample[key] for sample in examples], batch_first=True, padding_value=0)\n",
    "            for key in batch_keys}\n",
    "\n",
    "    #print(\"Keys after batching:\", batch.keys())\n",
    "    #print(\"After batching:\", len(batch[\"english_input_ids\"]))\n",
    "\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0334a9-eb92-4a16-b64e-e9a6bbe05893",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True, collate_fn=collator)\n",
    "\n",
    "for batch in train_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b4e2a0-5a59-4ecd-8aee-81fa885618bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[\"input_ids\"].shape,\\\n",
    "batch[\"attention_mask\"].shape,\\\n",
    "batch[\"labels\"].shape,\\\n",
    "batch[\"labels_attention_mask\"].shape,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62b96b3-1585-4355-882c-13b5d1381027",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecbc194-4538-4a2e-b1b9-a3d0554af667",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64125f85-7eff-4d40-91be-b950a0387998",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = transformers.T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "# we need randomly initilialised model\n",
    "model = transformers.T5ForConditionalGeneration(transformers.T5Config.from_pretrained(model_name)).to(device)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa48555e-ad54-49f7-9613-2856ec10ca9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_tokens = torch.arange(batch_size * 50).reshape(batch_size, 50).to(device)\n",
    "dummy_mask = torch.ones_like(dummy_tokens).to(device)\n",
    "dummy_prefix = torch.arange(batch_size * 35).reshape(batch_size, 35).to(device) + 22\n",
    "\n",
    "out = model(input_ids=dummy_tokens, attention_mask=dummy_mask, labels=dummy_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9829de39-84c3-497f-b6f3-68b7fdd54fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "out.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af77e67-3a69-4ff0-96af-cbd61cc64f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model, out, dummy_mask, dummy_tokens, dummy_prefix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa33c8c-a0db-44e6-ae15-333563d8b02d",
   "metadata": {},
   "source": [
    "## Training utils (not used yet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411d8de7-a84c-453a-84d4-0097953526b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_right(tensor, pad_token_id):\n",
    "    shifted_tensor = tensor.new_zeros(tensor.shape)\n",
    "    shifted_tensor[..., 1:] = tensor[..., :-1].clone()\n",
    "    shifted_tensor[..., 0] = pad_token_id\n",
    "\n",
    "    return shifted_tensor\n",
    "\n",
    "class CustomTrainer(transformers.Seq2SeqTrainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        english_input_ids = inputs.get(\"input_ids\")\n",
    "        russian_input_ids = inputs.get(\"labels\")\n",
    "        english_attention_mask = inputs.get(\"attention_mask\")\n",
    "        russian_attention_mask = inputs.get(\"labels_attention_mask\")\n",
    "        \n",
    "        en_ru = model(\n",
    "            input_ids=english_input_ids,\n",
    "            attention_mask=english_attention_mask,\n",
    "            labels=russian_input_ids,\n",
    "            decoder_attention_mask=shift_right(russian_attention_mask, pad_token_id=0),\n",
    "        )\n",
    "\n",
    "        ru_en = model(\n",
    "            input_ids=russian_input_ids,\n",
    "            attention_mask=russian_attention_mask,\n",
    "            labels=english_input_ids,\n",
    "            decoder_attention_mask=shift_right(english_attention_mask, pad_token_id=0),   \n",
    "        )\n",
    "\n",
    "        loss = ru_en.loss + en_ru.loss\n",
    "\n",
    "        return (loss, {\"ru_en\": ru_en, \"en_ru\": en_ru}) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c926d2a6-4c2e-4aa1-b6bf-02647baa0109",
   "metadata": {},
   "source": [
    "## Evaluation utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede765b1-594f-41fc-bfeb-5c02b44dc23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [[label.strip()] for label in labels]\n",
    "\n",
    "    return preds, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc288f8-58e8-4fd8-a44f-e2d298787300",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"sacrebleu\")\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
    "\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    result = {\"bleu\": result[\"score\"]}\n",
    "\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    result = {k: round(v, 4) for k, v in result.items()}\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a24aa0-ef65-4a14-95af-67348863502a",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89c393a-9b75-4a2c-a566-65a7238ff3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = transformers.Seq2SeqTrainingArguments(\n",
    "    output_dir=f\"./results/baseline-{model_name}\",\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    gradient_accumulation_steps=max(1, 16 // batch_size),\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.1,\n",
    "    logging_steps=10,\n",
    "    predict_with_generate=True,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    seed=SEED,\n",
    "    data_seed=SEED,\n",
    "    fp16=True, \n",
    "    #remove_unused_columns=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19599672-cadd-4774-885f-fce7ab219a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = transformers.T5ForConditionalGeneration(transformers.T5Config.from_pretrained(model_name)).to(device)\n",
    "\n",
    "opt = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=training_args.learning_rate, \n",
    "    weight_decay=training_args.weight_decay\n",
    ")\n",
    "\n",
    "scheduler = transformers.get_cosine_schedule_with_warmup(optimizer=opt, \n",
    "    num_warmup_steps=len(train_loader) * training_args.num_train_epochs // 5, \n",
    "    num_training_steps=len(train_loader) * training_args.num_train_epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3440f65b-c20e-4557-885b-1c87a9d7b3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = transformers.Seq2SeqTrainer(\n",
    "    model=model, \n",
    "    args=training_args, \n",
    "    data_collator=collator, \n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    optimizers=(opt, scheduler),\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1085a055-e2ad-4f2e-b216-beef183fb151",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer.train(ignore_keys_for_eval=[\"labels_attention_mask\"])\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791cf0c4-cfab-4061-833b-d9768400b0d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cyc)",
   "language": "python",
   "name": "cyc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
